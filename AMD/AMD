import cv2
import numpy as np
import time

def separable_gaussian_blur(image, kernel_size, sigma):
    """
    Applies separable Gaussian blur using two 1D convolutions.
    """
    k = cv2.getGaussianKernel(kernel_size, sigma)
    blurred = cv2.filter2D(image, -1, k)  # Blur in X direction
    blurred = cv2.filter2D(blurred, -1, k.T)  # Blur in Y direction
    return blurred

def create_static_mask(rows, cols):
    """
    Create a static mask with constant organic extensions.
    """
    np.random.seed(42)  # Fixed seed for consistent results
    center_x, center_y = cols // 2, rows // 2

    # Base radii for the central spot
    base_radius_x, base_radius_y = 80, 60
    max_radius_x, max_radius_y = 130, 100

    y, x = np.ogrid[:rows, :cols]
    distance_x = ((x - center_x) / base_radius_x) ** 2
    distance_y = ((y - center_y) / base_radius_y) ** 2
    distance = np.sqrt(distance_x + distance_y)

    # Create mask for the central spot
    mask = np.zeros((rows, cols), dtype=np.float32)
    mask[distance < 1] = 1
    transition_region = (distance >= 1) & (distance < max_radius_x / base_radius_x)
    mask[transition_region] = 1 - ((distance[transition_region] - 1) /
                                   ((max_radius_x / base_radius_x) - 1))

    # Add organic extensions
    extension_probability = 0.005
    random_mask = np.random.rand(rows, cols) < extension_probability
    random_indices = np.where((mask > 0.5) & (mask < 1) & random_mask)
    for y_ext, x_ext in zip(*random_indices):
        blob_radius = np.random.randint(5, 15)
        cv2.circle(mask, (x_ext, y_ext), blob_radius, 1, -1)

    # Apply Gaussian blur to smooth transitions
    kernel_size = 51
    sigma = 0
    mask = separable_gaussian_blur(mask, kernel_size, sigma)

    return mask

def simulate_late_amd_with_subtle_distortion_on_video(video_path, output_path):
    # Open the video file
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Failed to open video: {video_path}")
        return

    # Get video properties
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Define the codec and create a VideoWriter object
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    # Create a static mask
    mask = create_static_mask(frame_height, frame_width)

    total_processing_time = 0
    processed_frames = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        start_time = time.time()

        # Apply the static mask to create the faded spot
        faded_spot = frame * (1 - mask[..., None])

        # Step 2: Apply subtle distortion to the video content only
        amplitude, wavelength = 2, 100
        shift_x = (amplitude * np.sin(2 * np.pi * np.arange(frame_height)[:, None] / wavelength)).astype(int)
        shift_y = (amplitude * np.cos(2 * np.pi * np.arange(frame_width)[None, :] / wavelength)).astype(int)

        y_indices, x_indices = np.meshgrid(np.arange(frame_height), np.arange(frame_width), indexing='ij')
        new_x = np.clip(x_indices + shift_x, 0, frame_width - 1)
        new_y = np.clip(y_indices + shift_y, 0, frame_height - 1)

        # Apply distortion after masking
        distorted_frame = faded_spot[new_y, new_x]

        end_time = time.time()
        total_processing_time += (end_time - start_time)
        processed_frames += 1

        # Write the processed frame to the output video
        out.write(distorted_frame.astype(np.uint8))

    # Release resources
    cap.release()
    out.release()

    # Calculate average processing time and FPS
    avg_processing_time = total_processing_time / processed_frames
    overall_fps = processed_frames / total_processing_time
    print(f"Average processing time per frame: {avg_processing_time:.4f} seconds")
    print(f"Overall FPS: {overall_fps:.2f}")

# Test the function with a video file
video_path = r"C:\Users\pc\Downloads\WhatsApp Video 2024-11-30 at 23.04.32_ebe3b33d.mp4"
output_path = r"C:\Users\pc\Downloads\amd_output.mp4"
simulate_late_amd_with_subtle_distortion_on_video(video_path, output_path)
