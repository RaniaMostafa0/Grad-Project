import cv2
import numpy as np
import time

def separable_gaussian_blur(image, kernel_size, sigma):
    """
    Applies separable Gaussian blur using two 1D convolutions.
    """
    k = cv2.getGaussianKernel(kernel_size, sigma)
    blurred = cv2.filter2D(image, -1, k)  # Blur in X direction
    blurred = cv2.filter2D(blurred, -1, k.T)  # Blur in Y direction
    return blurred

def simulate_late_amd_with_subtle_distortion_on_video(video_path, output_path):
    # Open the video file
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Failed to open video: {video_path}")
        return

    # Get video properties
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Define the codec and create a VideoWriter object
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    total_processing_time = 0
    processed_frames = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        start_time = time.time()

        # Get image dimensions
        rows, cols = frame.shape[:2]
        center_x, center_y = cols // 2, rows // 2

        # Step 1: Create a mask for the black spot and extensions
        y, x = np.ogrid[:rows, :cols]
        base_radius_x, base_radius_y = 80, 60
        max_radius_x, max_radius_y = 130, 100

        distance_x = ((x - center_x) / base_radius_x) ** 2
        distance_y = ((y - center_y) / base_radius_y) ** 2
        distance = np.sqrt(distance_x + distance_y)

        mask = np.zeros((rows, cols), dtype=np.float32)
        mask[distance < 1] = 1
        transition_region = (distance >= 1) & (distance < max_radius_x / base_radius_x)
        mask[transition_region] = 1 - ((distance[transition_region] - 1) /
                                       ((max_radius_x / base_radius_x) - 1))

        extension_probability = 0.005
        random_mask = np.random.rand(rows, cols) < extension_probability
        random_indices = np.where((mask > 0.5) & (mask < 1) & random_mask)
        for y_ext, x_ext in zip(*random_indices):
            blob_radius = np.random.randint(5, 15)
            cv2.circle(mask, (x_ext, y_ext), blob_radius, 1, -1)

        kernel_size = 51
        sigma = 0
        mask = separable_gaussian_blur(mask, kernel_size, sigma)

        faded_spot = frame * (1 - mask[..., None])

        # Step 2: Apply subtle distortion
        amplitude, wavelength = 2, 100
        shift_x = (amplitude * np.sin(2 * np.pi * np.arange(rows)[:, None] / wavelength)).astype(int)
        shift_y = (amplitude * np.cos(2 * np.pi * np.arange(cols)[None, :] / wavelength)).astype(int)

        y_indices, x_indices = np.meshgrid(np.arange(rows), np.arange(cols), indexing='ij')
        new_x = np.clip(x_indices + shift_x, 0, cols - 1)
        new_y = np.clip(y_indices + shift_y, 0, rows - 1)

        distorted_frame = faded_spot[new_y, new_x]

        end_time = time.time()
        total_processing_time += (end_time - start_time)
        processed_frames += 1

        # Write the processed frame to the output video
        out.write(distorted_frame.astype(np.uint8))

    # Release resources
    cap.release()
    out.release()

    # Calculate average processing time and FPS
    avg_processing_time = total_processing_time / processed_frames
    overall_fps = processed_frames / total_processing_time
    print(f"Average processing time per frame: {avg_processing_time:.4f} seconds")
    print(f"Overall FPS: {overall_fps:.2f}")

# Test the function with a video file
video_path = r"C:\Users\pc\Downloads\WhatsApp Video 2024-11-30 at 23.04.32_ebe3b33d.mp4"
output_path = r"C:\Users\pc\Downloads\images\amd_output.mp4"
simulate_late_amd_with_subtle_distortion_on_video(video_path, output_path)
