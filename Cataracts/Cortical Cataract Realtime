import cv2
import numpy as np
import time
from IPython.display import display, clear_output
from PIL import Image
from threading import Thread, Event
from queue import Queue


def apply_glare_and_halo(image, mask, halo_intensity=0.6, glare_intensity=0.4, glare_blur=5):
    """
    Applies glare and halo effect to the bright areas of the image (optimized).
    """
    mask_3channel = cv2.merge([mask, mask, mask])

    # Add a halo effect with a smaller blur kernel for speed
    halo_effect = cv2.GaussianBlur(mask_3channel, (glare_blur, glare_blur), 0)

    # Blend the halo effect
    glare_halo = cv2.addWeighted(image, 1, halo_effect, halo_intensity, 0)

    # Apply glare with a smaller intensity for less overhead
    glare_overlay = np.full_like(image, (255, 255, 255), dtype=np.uint8)
    glare_effect = cv2.addWeighted(image, 1 - glare_intensity, glare_overlay, glare_intensity, 0)

    return cv2.addWeighted(glare_halo, 1, glare_effect, 0.5, 0)


def decrease_contrast(image, factor=0.6):
    """
    Reduces contrast while maintaining performance.
    """
    gray_mean = np.mean(image, axis=(0, 1), dtype=np.float32)
    blended = cv2.addWeighted(image, factor, np.full_like(image, gray_mean, dtype=np.uint8), 1 - factor, 0)
    return blended


def process_frame(frame):
    """
    Processes a single frame with flipping, glare, halo, and contrast adjustment.
    Optimized for lower latency.
    """
    flipped_frame = cv2.flip(frame, 1)

    # Convert to grayscale for mask generation
    gray_image = cv2.cvtColor(flipped_frame, cv2.COLOR_BGR2GRAY)

    # Create a mask for bright areas
    _, bright_mask = cv2.threshold(gray_image, 220, 255, cv2.THRESH_BINARY)

    # Apply glare and halo effect
    glare_halo = apply_glare_and_halo(flipped_frame, bright_mask)

    # Reduce contrast
    final_frame = decrease_contrast(glare_halo)

    return final_frame


def display_frame_in_notebook(frame, max_width=1280, max_height=720):
    """
    Display the frame in Jupyter Notebook without latency issues.
    """
    height, width = frame.shape[:2]
    scale = min(max_width / width, max_height / height)
    new_width, new_height = int(width * scale), int(height * scale)

    resized_frame = cv2.resize(frame, (new_width, new_height))

    # Flip again before displaying (to ensure mirroring)
    frame_rgb = cv2.cvtColor(cv2.flip(resized_frame, 1), cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(frame_rgb)

    clear_output(wait=True)
    display(pil_image)


def video_reader(cap, frame_queue, stop_event):
    """
    Reads frames from the video capture and pushes only the latest frame.
    """
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            stop_event.set()
            break

        flipped_frame = cv2.flip(frame, 1)  # Flip immediately to reduce processing time later

        # Clear queue and insert only the latest frame (avoids delay)
        while not frame_queue.empty():
            frame_queue.get_nowait()

        frame_queue.put(flipped_frame)


def video_processor(frame_queue, stop_event, max_width=1280, max_height=720):
    """
    Processes frames in real-time while keeping latency low.
    """
    total_processing_time = 0
    frame_count = 0

    try:
        while not stop_event.is_set():
            if not frame_queue.empty():
                frame = frame_queue.get()

                start_time = time.time()
                processed_frame = process_frame(frame)
                display_frame_in_notebook(processed_frame, max_width, max_height)

                processing_time_frame = time.time() - start_time
                total_processing_time += processing_time_frame
                frame_count += 1

                # Print FPS (more responsive than before)
                fps = 1 / processing_time_frame if processing_time_frame > 0 else 0
                print(f"FPS: {fps:.2f}", end='\r')

    except KeyboardInterrupt:
        stop_event.set()

    finally:
        if frame_count > 0:
            avg_processing_time = total_processing_time / frame_count
            overall_fps = frame_count / total_processing_time
            print(f"\nAverage processing time per frame: {avg_processing_time:.4f} seconds")
            print(f"Real-time processing FPS: {overall_fps:.2f}")


def realtime_video_processing():
    """
    Real-time processing of video frames with minimal latency.
    """
    cap = cv2.VideoCapture(1)  # Use 0 for default webcam

    if not cap.isOpened():
        print("Failed to open webcam.")
        return

    frame_queue = Queue(maxsize=1)  # Store only the latest frame to minimize lag
    stop_event = Event()

    reader_thread = Thread(target=video_reader, args=(cap, frame_queue, stop_event))
    reader_thread.start()

    try:
        video_processor(frame_queue, stop_event)

    except KeyboardInterrupt:
        print("\nExiting real-time video processing.")

    finally:
        stop_event.set()
        reader_thread.join()
        cap.release()


# Run optimized real-time processing
realtime_video_processing()
