import cv2
import numpy as np
import time
from IPython.display import display, clear_output
from PIL import Image
import threading

def precompute_blur_mask(shape, downscale_factor=0.5, x_offset=20, y_offset=-10):
    h, w = int(shape[0] * downscale_factor), int(shape[1] * downscale_factor)
    center_x, center_y = w // 2 + x_offset, h // 2 + y_offset
    y, x = np.ogrid[:h, :w]
    distance_from_center = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
    blur_mask = np.exp(-(distance_from_center ** 2) / (2 * (w // 6) ** 2))  # Increased denominator for milder blur
    return blur_mask.astype(np.float32), downscale_factor

def precompute_distortion_map(shape, x_offset=20, y_offset=-10, sine_frequency=2, cosine_frequency=2):
    h, w = shape[:2]
    center_x, center_y = w // 2 + x_offset, h // 2 + y_offset
    radius = min(h, w) // 2.0  # Increased radius for milder distortion

    x, y = np.meshgrid(np.arange(w), np.arange(h))
    distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
    fade_factor = np.clip((radius - distance) / radius, 0, 1)

    distortion_strength_sin, distortion_strength_cos = 0.6, 0.8  # Reduced strengths for milder effect
    amplitude_x = np.sin(2 * np.pi * (y - center_y) / h * sine_frequency) * 10 * distortion_strength_sin
    amplitude_y = np.cos(2 * np.pi * (x - center_x) / w * cosine_frequency) * 10 * distortion_strength_cos

    distortion_x = amplitude_x * fade_factor
    distortion_y = amplitude_y * fade_factor

    map_x = (x + distortion_x).astype(np.float32)
    map_y = (y + distortion_y).astype(np.float32)
    return map_x, map_y

def apply_central_micropsia(image, x_offset=20, y_offset=-10, radius_ratio=3.5, scaling_factor=0.9):
    """
    Simulate central micropsia by scaling down the central region of the image, ensuring smooth blending.
    """
    h, w = image.shape[:2]
    center_x, center_y = int(w // 2 + x_offset), int(h // 2 + y_offset)
    radius = int(min(h, w) // radius_ratio)

    # Extract the central region
    x_start, x_end = max(center_x - radius, 0), min(center_x + radius, w)
    y_start, y_end = max(center_y - radius, 0), min(center_y + radius, h)
    central_region = image[y_start:y_end, x_start:x_end]

    # Scale down the central region
    scaled_size = (int(central_region.shape[1] * scaling_factor), int(central_region.shape[0] * scaling_factor))
    scaled_region = cv2.resize(central_region, scaled_size, interpolation=cv2.INTER_LINEAR)

    # Create a blank region and paste the scaled region in the center
    blended_region = central_region.copy()
    start_x = (central_region.shape[1] - scaled_region.shape[1]) // 2
    start_y = (central_region.shape[0] - scaled_region.shape[0]) // 2
    blended_region[start_y:start_y + scaled_region.shape[0], start_x:start_x + scaled_region.shape[1]] = scaled_region

    # Create a feathered blending mask
    mask = np.zeros((central_region.shape[0], central_region.shape[1]), dtype=np.float32)
    scaled_radius = int(radius * scaling_factor * 0.9)  # Adjusted to match scaled region
    cv2.circle(mask, (central_region.shape[1] // 2, central_region.shape[0] // 2), scaled_radius, 1, -1)
    mask = cv2.GaussianBlur(mask, (71, 71), 30)  # Increased sigma for smoother transition
    mask_3d = cv2.merge([mask] * 3)

    # Blend the scaled region back into the image using the mask
    blended_region = (central_region * (1 - mask_3d) + blended_region * mask_3d).astype(np.uint8)

    # Place the blended region back into the original image
    result = image.copy()
    result[y_start:y_end, x_start:x_end] = blended_region

    return result


def apply_realistic_combined_effect(image, blur_mask, map_x, map_y, downscale_factor, scaling_factor=0.9):
    """
    Combine central distortion, blurring, and micropsia into one effect.
    """
    h, w = image.shape[:2]

    # Apply distortion
    distorted_image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

    # Apply central micropsia
    distorted_micropsia = apply_central_micropsia(distorted_image, x_offset=20, y_offset=-10, scaling_factor=scaling_factor)

    # Apply blurring
    small_image = cv2.resize(distorted_micropsia, None, fx=downscale_factor, fy=downscale_factor)
    small_blurred = cv2.GaussianBlur(small_image, (15, 15), 0)

    # Blend the blurred and original regions
    mask_3d = cv2.merge([blur_mask] * 3)
    blended_small = cv2.convertScaleAbs(small_image * (1 - mask_3d) + small_blurred * mask_3d)

    return cv2.resize(blended_small, (image.shape[1], image.shape[0]))

def display_frame_in_notebook(frame):
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(frame_rgb)
    clear_output(wait=True)
    display(pil_image)

def process_webcam_feed():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error: Could not access the webcam.")
        return

    ret, sample_frame = cap.read()
    if not ret:
        print("Error: Failed to capture initial frame.")
        cap.release()
        return

    target_height = 720
    target_width = int(sample_frame.shape[1] * (target_height / sample_frame.shape[0]))
    blur_mask, downscale_factor = precompute_blur_mask((target_height, target_width), x_offset=20, y_offset=-10)
    map_x, map_y = precompute_distortion_map((target_height, target_width), x_offset=20, y_offset=-10)

    processed_frame = None
    processing_done = threading.Event()

    def process_frame(frame):
        nonlocal processed_frame
        # Flip the frame horizontally
        flipped_frame = cv2.flip(frame, 1)
        processed_frame = apply_realistic_combined_effect(flipped_frame, blur_mask, map_x, map_y, downscale_factor, scaling_factor=0.9)
        processing_done.set()

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("Error: Failed to capture frame.")
                break

            frame_resized = cv2.resize(frame, (target_width, target_height))

            processing_done.clear()
            thread = threading.Thread(target=process_frame, args=(frame_resized,))
            thread.start()

            if processing_done.wait(timeout=1 / 30):
                display_frame_in_notebook(processed_frame)

    except KeyboardInterrupt:
        print("\nExiting real-time video processing.")

    finally:
        cap.release()

if __name__ == "__main__":
    process_webcam_feed()
