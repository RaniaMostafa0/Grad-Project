import cv2
import numpy as np
import time
from IPython.display import display, clear_output
from PIL import Image
import threading

# Precompute blur mask for consistent downscaling and blur region offset
def precompute_blur_mask(shape, downscale_factor=0.5, x_offset=20, y_offset=10):
    h, w = int(shape[0] * downscale_factor), int(shape[1] * downscale_factor)
    center_x, center_y = w // 2 + x_offset, h // 2 + y_offset
    y, x = np.ogrid[:h, :w]
    distance_from_center = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
    blur_mask = np.exp(-(distance_from_center ** 2) / (2 * (w // 4) ** 2))
    return blur_mask.astype(np.float32), downscale_factor

# Apply combined distortion and blur effect
def apply_realistic_combined_effect(image, blur_mask, downscale_factor, x_offset=20, y_offset=10):
    h, w = image.shape[:2]
    center_x, center_y = w // 2 + x_offset, h // 2 + y_offset
    radius = min(h, w) // 4  # Reduce distortion radius

    # Create meshgrid for the image
    x, y = np.meshgrid(np.arange(w), np.arange(h))
    
    # Calculate distance from center
    distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
    
    # Mask for pixels within the distortion radius
    mask = distance < radius
    
    # Apply weaker distortion
    fade_factor = (radius - distance) / radius  # Smooth transition from center to edge
    fade_factor[fade_factor < 0] = 0  # Prevent negative values

    amplitude_x = np.sin(2 * np.pi * (y - center_y) / h * 4) * 5  # Reduced amplitude
    amplitude_y = np.cos(2 * np.pi * (x - center_x) / w * 4) * 5  # Reduced amplitude

    # Distortion intensity is now weaker
    distortion_x = amplitude_x * fade_factor
    distortion_y = amplitude_y * fade_factor

    # Apply the distortion using these dynamic values
    map_x = (x + distortion_x).astype(np.float32)
    map_y = (y + distortion_y).astype(np.float32)

    # Distort the image using remapping
    distorted_image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

    # Mask the distorted image to only affect the central region
    distorted_image[~mask] = image[~mask]  # Keep original pixels outside the central region

    # Downscale the image and mask for faster processing
    small_image = cv2.resize(distorted_image, None, fx=downscale_factor, fy=downscale_factor)
    small_blurred = cv2.GaussianBlur(small_image, (21, 21), 0)  # Weaker blur effect

    # Blend the original and blurred images using the mask
    mask_3d = cv2.merge([blur_mask] * 3)  # Convert to 3-channel mask
    blended_small = cv2.convertScaleAbs(
        small_image * (1 - mask_3d) + small_blurred * mask_3d
    )

    # Upscale back to original size
    return cv2.resize(blended_small, (image.shape[1], image.shape[0]))

def display_frame_in_notebook(frame):
    """Display a frame inline in Jupyter Notebook."""
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for PIL
    pil_image = Image.fromarray(frame_rgb)
    clear_output(wait=True)  # Clear the previous output
    display(pil_image)

def simulate_macular_pucker_webcam():
    # Open the webcam (Use 1 for external, 0 for internal webcam)
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("Failed to open webcam.")
        return
    print("Press 'Kernel Interrupt' to stop the display.")
    
    # Precompute the blur mask
    ret, sample_frame = cap.read()
    if not ret:
        print("Failed to capture frame for initialization.")
        cap.release()
        return
    
    target_height = 720
    target_width = int(sample_frame.shape[1] * (target_height / sample_frame.shape[0]))
    frame_resized = cv2.resize(sample_frame, (target_width, target_height))
    blur_mask, downscale_factor = precompute_blur_mask(frame_resized.shape, x_offset=70, y_offset=40)
    
    # Frame processing thread
    processed_frame = None
    processing_done = threading.Event()

    def process_frame(frame):
        """Background thread to apply the distortion and blur effect to the frame."""
        nonlocal processed_frame
        # Flip the frame horizontally
        frame_flipped = cv2.flip(frame, 1)
        processed_frame = apply_realistic_combined_effect(frame_flipped, blur_mask, downscale_factor)
        processing_done.set()

    try:
        prev_time = time.time()
        while True:
            start_time = time.time()
            ret, frame = cap.read()
            if not ret:
                print("Failed to capture frame.")
                break
            
            # Resize frame to consistent size
            frame_resized = cv2.resize(frame, (target_width, target_height))
            
            # Start processing in a separate thread (reuse the thread instead of creating new ones every frame)
            processing_done.clear()
            thread = threading.Thread(target=process_frame, args=(frame_resized,))
            thread.start()
            
            # Display processed frame after distortion and blur if available
            if processing_done.wait(timeout=1 / 25):  # Wait for the previous frame or timeout
                display_frame_in_notebook(processed_frame)
            
            # Calculate FPS
            end_time = time.time()
            frame_time = end_time - start_time
            fps = 1 / frame_time
            print(f"FPS: {fps:.2f}")
            
            # Display FPS for debugging
            if fps > 25:
                print("Optimal FPS achieved!")
                break
    except KeyboardInterrupt:
        print("Exiting simulation.")
    cap.release()

# Run the webcam simulation
simulate_macular_pucker_webcam()
